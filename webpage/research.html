<!DOCTYPE html>
<html>
<head>

    <title>Sina Mohseni</title>
	
	<meta name="author" content="Sina Mohseni" />
	<meta name="description" content="personal webpage" />
	<link rel="stylesheet" href="./icons.css" type="text/css" />
	<link rel="stylesheet" href="./style.css" type="text/css" />
	

	
</head>
<body>

	<div id="page">
		<div id="logo">
			<h1><a href="http://people.tamu.edu/~sina.mohseni/" id="logoLink">Sina Mohseni</a></h1>
		</div>
		<div id="nav">
			<ul>
				<li><a href="../index.html">Home</a></li>
				<li><a href="./research.html">Research</a></li>
				<li><a href="./publications.html">Publications</a></li>
				<li><a href="../papers/cv.pdf">Resume</a></li>
			</ul>	
		</div>
		
		<!--                          //////////////// Explainable Machine Learning //////////////////                         -->
		<div id="content">  <!-- class = parallel -->
			<h1><b>Interpretable Machine Learning</b></h1>


			<!--  //////////////// Sub-project //////////////////                         -->
			
			<div class = parallel style="width: 100%">  
				<div class = image>
					<br>
					<br>
					<br>
					<br>
					<a><img  src="./model.png" width="380"></a>	
					<!-- <a href="" target="_blank"><img  src="./tool2.png" width="380"></a> -->
					<br>
					<br>
					<div  id="links">  <!-- "margin-left:2em -->
						<a class="author-social2" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Paper </a>
						<a href="https://docs.google.com/presentation/d/1FDNgCdUjY05_-KrA_h8epe8WXb-fOeYsno2n0yrCBLs/edit#slide=id.p" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Presentation</a>
						<a href="https://docs.google.com/spreadsheets/d/1PP1aSOlbyhlSB1KtgtmOmuUpKMeZy7EvgfDMcwHqd3k/edit#gid=0" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Reference Table</a>
						<!-- <a href="https://github.com/SinaMohseni/Text-classification-explanation-evaluation" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>   -->
						<!-- <a href="https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a> -->
						<!-- <a href="http://people.tamu.edu/~sina.mohseni/expevl" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a> -->
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<!-- <br>
					<br> -->
					<h5><b>Evaluation Methods for Interpretable Machine Learning</b></h5>			

					<p>
						The need for interpretable and accountable intelligent system gets sensible as artificial intelligence plays more role in human life.
						Explainable artificial intelligence systems can be a solution by self-explaining the reasoning behind the decisions and predictions of the intelligent system.
						Researchers from different disciplines work together to define, design and evaluate interpretable intelligent systems for the user.
						Our work supports the different evaluation goals in interpretable machine learning research by a thorough review of evaluation methodologies used in machine-explanation research across the fields of human-computer interaction, visual analytics, and machine learning.
						We present a 2D categorization of interpretable machine learning evaluation methods and show a mapping between user groups and evaluation measures.
						Further, we address the essential factors and steps for a right evaluation plan by proposing a nested model for design and evaluation of explainable artificial intelligence systems.
					</p>
					<p>
						Our models for design and evaluation of interpretable machine learning model is consist of three layers. 
						The innermost layer aims to design interpretable models (or generate machine explanations) and verify explanations trustworthiness.
						Machine learning experts contribute by designing interpretable models and evaluate the explanations' trustworthiness.
						This second layer can be viewed as the translator for an XAI system.
						The goal of the middle layer is to design human understandable explanations, explanation agents and interfaces, and visual analytics tools and verify their usability.
						HCI and visual analytics designers employ user-centered design principles and verify designs with subjective evaluations of satisfaction and   mental models for different types of users.
						The outermost layer focuses on outcomes of using the XAI system.
						The aim of this layer is to verify what the intelligible design has gained for the end-user.
						In other words, the goal is to measure XAI system's impact on user trust, reliance, and human-machine  performance in performing tasks.
						Evaluation designs in this layer are very much dependent on the application domain, and various subjective and objective measures can be used to evaluate XAI system success with regard to the expected outcomes.
					</p>

					
				</div>
			</div>

			<!--  //////////////// Sub-project 1 //////////////////                         -->
			
			<div class = parallel style="width: 100%">  
				<div class = image>
					<a href="https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark" target="_blank"><img  src="./benchmark.png" width="380"></a>
					<br>
					<br>
					<div  id="links">  <!-- "margin-left:2em -->
						<a class="author-social2" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Paper </a>
						<a href="../papers/Benchmark.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Short Paper</a>
						<!-- <a href="https://github.com/SinaMohseni/Text-classification-explanation-evaluation" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>   -->
						<a href="https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a>
						<!-- <a href="http://people.tamu.edu/~sina.mohseni/expevl" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a> -->
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<!-- <br>
					<br> -->
					<h5><b>A Human Grounded Evaluation Benchmark for Machine Learning Explanations</b></h5>			

					<p>
						With the recent and continuing advancements in robust deep learning methods, the prominence of artificial intelligence is growing fast for automated decision-making in many applications.
						However, while designers can use feature engineering in conventional machine learning to maintain a degree of control over how the model learns, human review of training data and features is mostly dismissed for deep learning algorithms due to the highly complex architectures and large scale of training data.
						Consequently, the lack of human supervision can result in problems such as biased algorithms or unfair algorithmic decision-making.
						My research takes a novel approach by leveraging machine explanations along with human input to introduce machine explanations score. 
					</p>
					<p> 
						Explanations score is a measure to evaluate machine learning model reliability in terms of model bias and variance.
						We also propose our human annotation benchmark as an evaluation test set for machine explanations.
						In two different case studies, we demonstrate the utility and effectiveness of explanations score and human-annotation benchmark for recognizing overfitted and underfitted models.
						Human grounded evaluation are type of evaluation where users should decide explanation quality.						
						In our benchmark, we present explanations for a subset of articles from 
						<a href="http://qwone.com/~jason/20Newsgroups/" target="_blank">20 Newsgroup dataset</a> 
						and also a subset of 
						images from
						<a href="http://www.image-net.org/" target="_blank">ImageNet</a>  
						datasets.
						For the text data, users performed text annotations (highlighting) on the words which were related to the article category.
						On the image data, users were highlighting image saliency 
						Benchmark is 
						<a href="https://github.com/SinaMohseni/Text-classification-explanation-evaluation" target="_blank">available online</a> 
						for research purposes and you can find more detailed description and results in our paper.
					</p>

					
				</div>
			</div>

			<!--  //////////////// Sub-project 2 //////////////////                         -->
			
			<div class = parallel style="width: 100%">  
				<div class = image>
					<br>
					<br>
					<a><img  src="./tool2.png" width="380"></a>	
					<!-- <a href="" target="_blank"><img  src="./tool2.png" width="380"></a> -->
					<br>
					<br>
					<div  id="links">  <!-- "margin-left:2em -->
						<a class="author-social2" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Paper </a>
						<a href="https://docs.google.com/presentation/d/1FDNgCdUjY05_-KrA_h8epe8WXb-fOeYsno2n0yrCBLs/edit#slide=id.p" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Presentation</a>
						<!-- <a href="https://github.com/SinaMohseni/Text-classification-explanation-evaluation" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>   -->
						<!-- <a href="https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a> -->
						<!-- <a href="http://people.tamu.edu/~sina.mohseni/expevl" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a> -->
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<!-- <br>
					<br> -->
					<h5><b>Interpretable Fake News Detection</b></h5>			

					<p>
						Explainable Artificial Intelligence (XAI) systems aim to provide users with information to help them better understand computational models and reason about why outputs were generated.
						However, there are many different ways an XAI interface might present explanations, which makes designing an appropriate and effective interface an important and challenging task.
						Our work investigates how different types and amounts of explanatory information affects user ability to utilize explanations to understand system behavior and improve task performance in the fake news detection application.

					</p>
					<p>
						For this project I designed an interface for the end-users to review machine learning explanations generated form a fake news classifier.
						For the next step, we designed a controlled experiment and participants were tasked to use the system to assess news statements as well as to learn to predict the output of the machine learning algorithm.
						The experiment compared variations of the interface offering various types of explanatory information to contribute empirical data about how explanation detail can influence utility.
						Our studies show that more explanation information improved participant understanding of the AI models, but the benefits came at the cost of time and attention needed to make sense of the explanation.
					</p>

					
				</div>
			</div>

			<!--  //////////////// Sub-project 3 ? //////////////////                         -->

			<!-- <div style="margin-bottom: 300px"> </div> -->
						
		</div>

		<br>
		<br>

		<!--                          //////////////// Crowdsouced Data Annotation //////////////////                         -->
		<div id="content">  <!-- class = parallel -->
			<h1><b>Crowdsouced Data Annotation</b></h1>

			<!--  //////////////// Sub-project 1 //////////////////                         -->
			
			<div class = parallel style="width: 100%">  
				<div class = image>
					<br>
					<br><br>
					<br>
					<a><img  src="./lidar.png" width="380"></a>
					<br>
					<br>
					<div  id="links">  <!-- "margin-left:2em -->
						<a href="https://docs.google.com/presentation/d/10I2dJvPuQar8zB2KMC5MAHKECV0N6gBRIeYlTA8Ge5E/edit#slide=id.p" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Short Presentation</a>
						<!-- <a href="https://github.com/SinaMohseni/Text-classification-explanation-evaluation" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>   -->
						<!-- <a href="https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a> -->
						<!-- <a href="http://people.tamu.edu/~sina.mohseni/expevl" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a> -->
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<!-- <br>
					<br> -->
					<h5><b>LiDAR Point Cloud Annotation for Self-driving Car Applications</b></h5>			

					<p>
						I started this crowdsourcing LiDAR data annotation project on summer 2018 at Bosch RTC, Pittsburgh. 
						I Implemented a web based 3D LiDAR data annotation tool for crowdworkers to create training data for self-driving car applications.
        				I designed and implemented micro task and work flows for data annotation in Amazon Mechanical Turk.
        				Initiated micro-payments model and created an expert-pool of mTurk workers to increase user engagement and data quality.
						My work resulted in reduceing annotation cost from 2.4 cents per annotated object to 0.74 per annotated object.
						I increased annotation task submission rate from %57 to %84.
						Increased object annotation recall from 59% to 91%.
					</p>
					<p> 
						I designed an interactive user interface for visualizing 3D point cloud data from LiDAR sensor for the end-users using Three.js.
						I followed user-centered design together with agile development to collect feedback from my team, on-site user studies and later off-site mTurk crowd workers. 
						I deployed the tool on an AWS Apache server, created API calls and used MongoDB to manage, store, and retrieve annotation data in MongoDB.
						I tested the system in larger scale with mTruk workers and implemented multiple crowdsourcing techniques to increase data quality and reduce annotation cost.
						I verified annotation system with three goals: 1-annotation box rotation/scale/position error 2- Object annotation recall 3-annotation cost 4- annotation time.
					</p>

					
				</div>
			</div>
				  				<!-- ///////////// Next Project  /////////////   -->
			<!-- <div style="margin-bottom: 300px"> </div> -->
						
		</div>

		<br>
		<br>

		<!--                        ///////////// Provenance Threads  /////////////                 -->
		<div id="content"> 
			<h1><b>Analytic Provenance Visualization</b></h1>
			<div class = parallel style="width: 100%">  
				<div class = image>
					<br>
					<br>
					<br>
					<a href="http://people.tamu.edu/~sina.mohseni/provcluster" target="_blank"><img  src="./provcluster.png" width="480"></a>
					<br>
					<br> 
					<div  id="links" style="margin-left:1em">
						<!-- <a href="" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Full Paper</a> -->
						<!-- <a href="../papers/Provenance threads mohseni shortpaper.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Short Paper</a> -->
						<!-- <a href="./Provenance-threads-mohseni-poster.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-image-o fa-lg"></i> Poster</a> -->
						<br>
						<a href="https://github.com/SinaMohseni/Capturing-Knowledge-Through-User-Interaction-Logs" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/provcluster" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- <a href="https://vimeo.com/230839558" class="author-social2" target="_blank"><i class="fa fa-vimeo-square fa-lg" style="margin-left:1em"></i> Video</a> -->
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<br>
					<br>
					<h5><b>ProvCluster: Analysis History and Knowledge Visualization</b></h5>			
					<p>
						This early released visual analytics tool presents data and analysis history visualization in text analysis.
						Top view shows a scatter plot visualization of text documents that has been review by the analyst. 
						Bottom view shows a history of user interactions classified by their data topic.
						This tool helps to review analysis progress for team collaborations.
					</p>
					<p> 
						<br><br><br><br><br><br>
 					</p>
				</div>
			</div>


			<div class = parallel style="width: 100%">  
				<div class = image>
					<br>
					<br>
					<br>
					<a href="http://people.tamu.edu/~sina.mohseni/threads" target="_blank"><img  src="./threads.png" width="480"></a>
					<br>
					<br> 
					<div  id="links" style="margin-left:1em">
						<!-- <a href="" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Full Paper</a> -->
						<a href="../papers/Provenance threads mohseni shortpaper.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Short Paper</a>
						<!-- <a href="./Provenance-threads-mohseni-poster.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-image-o fa-lg"></i> Poster</a> -->
						<br>  
						<a href="https://github.com/SinaMohseni/Provenance-Threads" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/threads" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<a href="https://vimeo.com/230839558" class="author-social2" target="_blank"><i class="fa fa-vimeo-square fa-lg" style="margin-left:1em"></i> Video</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<br>
					<br>
					<h5><b>ProvThreads: Analysis History Visualization and Segmentation with User Interaction and Data Provenance</b></h5>			
					<p>
						This paper presents ProvThreads, a novel visual analytics tool that incorporates interactive topic modeling outcomes to
						illustrate relationships between user actions and analytic data.
						ProvThreads projects a series of continuous analysis paths to demonstrate both topic coverage and the progression of an investigation over time.
						We simplify high-dimension temporal event sequence data by combining data and user interaction records
					</p>
					<p> 
						Data topics are visualized with color treads and weighted user interactions form the threads shape. 
						Each thread indicates one topic (cluster of documents) in the corpus. 
						Topic threads gain height with small steps while the user is interacting with the topics. 
						Threads height show user's focus and interest on the topics at each moment.
						Topic threads loose height when the user moves to another topic to continue the analysis. 
						This visualization shows sequence of analysis topics and points the topic transitions which are used in provenance segmentation and meta-analysis.
 					</p>
				</div>
			</div>

			<div class = prjct_desc>  
				<div class = image>
					<!-- <br>
					<br> -->
					<br>
					<a href="http://people.tamu.edu/~sina.mohseni/heatmap" target="_blank"><img  src="./heatmap.png" width="480"></a>
					<br>
					<br>
					<div  id="links" style="margin-left:1em">
						<a href="https://github.com/SinaMohseni/Cluster-Topics-heatmap-visualization" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/heatmap" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					
					<h5><b>Cluster-Feature Heat Map Visualization in Clustering Tasks</b></h5>			
					<p>
						A cluster-feature heat map visualization to find overall features distribution in clusters.
 						Rows represent clusters and columns are features.
 						Each data point increases color intensity for the corresponding cluster and features.
 						Total number of data points in each cluster is given on the right side of the heat map.
 						In an document clustering task, lower topic feature distribution on each cluster means less variations of content in document clusters.
					</p>
					<p> 
					<br><br><br><br><br><br>
					</p>					
				</div>
			</div>


			<div class = prjct_desc>  
				<div class = image>
					<br>
					<br>
					<br>
					<a href="http://people.tamu.edu/~sina.mohseni/blocks" target="_blank"><img  src="./blocks.png" width="480"></a>
					<br>
					<br>
					<div  id="links" style="margin-left:1em">
						<a href="https://github.com/SinaMohseni/Interaction-blocks" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/blocks" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					
					<h5><b>Document Blocks: User Interaction Visualization for Document Exploration Tasks</b></h5>			
					<p>
						User interactions in analysis tasks are capable of representing how the user performed analysis tasks by means of user's methods and strategies.
						What user interactions are and how to capture them depends on the analysis task and the computer interface tool.
						Visualization tools help researchers to go through user interactions in time and reveal relations between user methods and strategies. 
					</p>
					<p> 
						This research is a simple visualization design to help with text analytic task post-analysis. 
						Detailed view of user interactions are used to help user visually identify any existing user interaction patterns, while overview of data helps with task segmentation. 
						We evaluated the performance for each view in user interaction pattern identification and strategy exploration. 
						Evaluation results show this visualization helped users in better understanding the analytic tasks and finding user’s methods and strategies.
					</p>					
				</div>
			</div>

			<br>

			<div class = prjct_desc style="float:left">  
				<div class = image>
					<br>
					<a href="http://people.tamu.edu/~sina.mohseni/docexplorer" target="_blank"><img  src="./explorer.png" width="480"></a>
					<br>
					<br>
					<div  id="links" style="margin-left:1em">
						<a href="https://research.arch.tamu.edu/analytic-provenance/datasets/" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a>
						<a href="../papers/Dataset.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Paper</a>
						<a href="http://people.tamu.edu/~sina.mohseni/docexplorer" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>

					<h5><b>Analytic Provenance Dataset</b></h5>			
					<p>
						This work is a public available analytic provenance dataset.
						We conducted a series of user studies involving an exploratory data analysis scenario with textual data. 
						User interactions logs and meta-data in this study are available for research purposes.
						
					</p>
					<p> 
						For the analysis scenarios, we selected data analysis tasks with sufficient complexity and scope to allow the exploration of various topics and hypotheses. 
						User think-alouds during the study are also included in this dataset.
						User analytic tasks are segmented in sub-tasks based on user think-alouds, video and audios captured during the studies.
					</p>

					
				</div>
			</div>
			<div class = no_parallel style="margin-bottom: 100px;" > </div>
		</div>
		<br>
		<br>

		<div id="footer">
			<p>
				Webpage created by <a href="http://people.tamu.edu/~sina.mohseni">Sina Mohseni</a>
				-- Last updat: Sept. 2018
			</p>
		</div>
	</div>
</body>
</html>