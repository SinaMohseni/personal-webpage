<!DOCTYPE html>
<html>
<head>

    <title>Sina Mohseni</title>
	
	<meta name="author" content="Sina Mohseni" />
	<meta name="description" content="personal webpage" />
	<link rel="stylesheet" href="./icons.css" type="text/css" />
	<link rel="stylesheet" href="./style.css" type="text/css" />
	

	
</head>
<body>

	<div id="page">
		<div id="logo">
			<h1><a href="http://people.tamu.edu/~sina.mohseni/" id="logoLink">Sina Mohseni</a></h1>
		</div>
		<div id="nav">
			<ul>
				<li><a href="../index.html">Home</a></li>
				<li><a href="./research.html">Research</a></li>
				<li><a href="./publications.html">Publications</a></li>
				<li><a href="./cv.pdf">Vita</a></li>
			</ul>	
		</div>
		
		<!--                          //////////////// Explainable Machine Learning //////////////////                         -->
		<div id="content">  <!-- class = parallel -->
			<h1><b>Interpretable Machine Learning</b></h1>
			<!--                          //////////////// Sub-project 1 //////////////////                         -->
			
			<div class = parallel style="width: 100%">  
				<div class = image>
					<img  src="./benchmark.png" width="380">
					<br>
					<br>
					<div  id="links">  <!-- "margin-left:2em -->
						<a href="https://github.com/SinaMohseni/Text-classification-explanation-evaluation" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a>
						<a href="http://people.tamu.edu/~sina.mohseni/txtevlsty" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<!-- <br>
					<br> -->
					<h5><b>A human grounded evaluation benchmark for text and image classifiers</b></h5>			

					<p>
						One can understand reseans behind machine learning systems output if it has a interpretable structure (gloablly interpretable) or individual outputs are presented with a decision reason (local explanations).
						This project is about generating an evaluation benchmark for interpretable machine learning systems.
						We aim to evaluate explanations generated by machine learning systems with human subjects.
						Human grounded evaluation are type of evaluation where users should decide explanation quality.
					</p>
					<p> 						
						In this benchmark, we present explanations for a subset of articles from 
						<a href="http://qwone.com/~jason/20Newsgroups/" target="_blank">20 Newsgroup dataset</a> 
						and also a subset of 
						images from
						<a href="http://cocodataset.org/#home" target="_blank"> COCO </a> 
						and 
						<a href="http://www.image-net.org/" target="_blank">ImageNet</a>  
						datasets.
						For the text data, users performed text annotations (highlighting) on the words which were related to the article category.
						On the image data, users were highlighting image saliency 
						Benchmark is 
						<a href="" target="_blank">available online</a> 
						for research purposes and you can find more detailed description and results in our paper.
					</p>

					
				</div>
			</div>


			<div class = parallel style="width: 100%">  
				<div class = image>
					<img  src="./ui-xai.png" width="380">
					<br>
					<br>
					<div  id="links" >  <!-- style="margin-left:2em" -->
						<a href="https://github.com/SinaMohseni/UI-Healthcare-Classification" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/xai-ui" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<a href="https://www.youtube.com/watch?v=U7Lrb5baeYs&t=" class="author-social2" target="_blank"><i class="fa fa-youtube-play fa-lg" style="margin-left:1em"></i> Video</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<h5><b>Interpretable Classification for Information Extraction from Online Healthcare Forums</b></h5>			
					<br>
					<p>
						Interpretable machine learning is a branch of mashin learning systems that are able to give explanations to 
						the user (human) about their output (decisions). 
						Why do we need explanations from machines? How can we obtain explanation from complex deep neural network? and How can we measure 
						quality of explanations? are interesting research questions in both HCI and Maching Learning communities.
					</p>
					<p> 
						This project is about designing a user interface for users in healthcare community.
						We design a user interface for text classifier which classifies articles from online healthcare forums into symptom and medication topics.
						The user interface highlights words and phrases related to 
						This user interface is built to support explanations from healthcare data classifiers presented in 
						<a href="https://www.hindawi.com/journals/jhe/2017/2460174/" target="_blank">this paper</a>
						from members of our XAI project team.

					</p>
				</div>
			</div>

			<!-- <div style="margin-bottom: 300px"> </div> -->
						
		</div>

		<br>
		<br>

		<!--                        ///////////// Provenance Threads  /////////////                 -->
		<div id="content"> 
			<h1><b>Analytic Provenance Visualization</b></h1>
		<div class = parallel style="width: 100%">  
				<div class = image>
					<img  src="./threads.png" width="480">
					<br>
					<br> 
					<div  id="links" style="margin-left:1em">
						<a href="" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Full Paper</a>
						<a href="./Provenance-threads-mohseni-shortpaper.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Short Paper</a>
						<!-- <a href="./Provenance-threads-mohseni-poster.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-image-o fa-lg"></i> Poster</a> -->
						<br>  
						<a href="https://github.com/SinaMohseni/Provenance-Threads" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/threads" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<a href="https://vimeo.com/230839558" class="author-social2" target="_blank"><i class="fa fa-vimeo-square fa-lg" style="margin-left:1em"></i> Video</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					<br>
					<br>
					<h5><b>Analysis History Visualization and Segmentation with User Interaction and Data Provenance</b></h5>			
					<p>
						This paper presents ProvThreads, a novel visual analytics tool that incorporates interactive topic modeling outcomes to
						illustrate relationships between user actions and analytic data.
						ProvThreads projects a series of continuous analysis paths to demonstrate both topic coverage and the progression of an investigation over time.
						We simplify high-dimension temporal event sequence data by combining data and user interaction records
					</p>
					<p> 
						Data topics are visualized with color treads and weighted user interactions form the threads shape. 
						Each thread indicates one topic (cluster of documents) in the corpus. 
						Topic threads gain height with small steps while the user is interacting with the topics. 
						Threads height show user's focus and interest on the topics at each moment.
						Topic threads loose height when the user moves to another topic to continue the analysis. 
						This visualization shows sequence of analysis topics and points the topic transitions which are used in provenance segmentation and meta-analysis.
 					</p>
				</div>
			</div>


			<div class = prjct_desc>  
				<div class = image>
					<img  src="./blocks.png" width="480">
					<br>
					<br>
					<div  id="links" style="margin-left:1em">
						<a href="https://github.com/SinaMohseni/Interaction-blocks" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-github-square fa-lg"></i> Github</a>  
						<a href="http://people.tamu.edu/~sina.mohseni/blocks" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>
					
					<h5><b>A Simple User Interaction Visualization for Document Exploration Tasks</b></h5>			
					<p>
						User interactions in analysis tasks are capable of representing how the user performed analysis tasks by means of user's methods and strategies.
						What user interactions are and how to capture them depends on the analysis task and the computer interface tool.
						Visualization tools help researchers to go through user interactions in time and reveal relations between user methods and strategies. 
					</p>
					<p> 
						This research is a simple visualization design to help with text analytic task post-analysis. 
						Detailed view of user interactions are used to help user visually identify any existing user interaction patterns, while overview of data helps with task segmentation. 
						We evaluated the performance for each view in user interaction pattern identification and strategy exploration. 
						Evaluation results show this visualization helped users in better understanding the analytic tasks and finding userâ€™s methods and strategies.
					</p>					
				</div>
			</div>

<br>

			<div class = prjct_desc style="float:left">  
				<div class = image>
					<img  src="./explorer.png" width="480">
					<br>
					<br>
					<div  id="links" style="margin-left:1em">
						<a href="https://research.arch.tamu.edu/analytic-provenance/datasets/" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-database"></i> Dataset</a>
						<a href="./Analytic Provenance Dataset.pdf" class="author-social2" target="_blank" style="margin-left:1em"><i class="fa fa-file-pdf-o fa-lg"></i> Short Paper</a>
						<a href="http://people.tamu.edu/~sina.mohseni/docexplorer" class="author-social2" target="_blank"><i class="fa fa-laptop fa-lg" style="margin-left:1em"></i> Demo</a>
						<!-- fa-vimeo-square -->
					</div>
				</div>
				<div class = no_parallel>

					<h5><b>Analytic Provenance Dataset</b></h5>			
					<p>
						This work is a public available analytic provenance dataset.
						We conducted a series of user studies involving an exploratory data analysis scenario with textual data. 
						User interactions logs and meta-data in this study are available for research purposes.
						
					</p>
					<p> 
						For the analysis scenarios, we selected data analysis tasks with sufficient complexity and scope to allow the exploration of various topics and hypotheses. 
						User think-alouds during the study are also included in this dataset.
						User analytic tasks are segmented in sub-tasks based on user think-alouds, video and audios captured during the studies.
					</p>

					
				</div>
			</div>
			<div class = no_parallel style="margin-bottom: 100px;" > </div>
		</div>
		<br>
		<br>

		<div id="footer">
			<p>
				Webpage created by <a href="http://people.tamu.edu/~sina.mohseni">Sina Mohseni</a>
				-- Last updat: December 2017
			</p>
		</div>
	</div>
</body>
</html>